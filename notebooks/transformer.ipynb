{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c03d03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a12ca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05cc8460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from hcrot import layers, optim\n",
    "from hcrot.dataset import *\n",
    "from hcrot.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b229e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_rate = 1e-3\n",
    "hidden_size = 32\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b7463e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./datasets/mnist_test.csv\")\n",
    "label = df['7'].to_numpy()\n",
    "df = df.drop('7', axis=1)\n",
    "dat = (df / 255.).to_numpy()\n",
    "\n",
    "dataset_len = len(dat)\n",
    "dat = dat.reshape(dataset_len, 28, 28).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a05a5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image, test_image = dat[:5000], dat[8001:9001]\n",
    "train_label, test_label = label[:5000], label[8001:9001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6959f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = Dataloader(train_image, train_label, batch_size=50, shuffle=True)\n",
    "testloader = Dataloader(test_image, test_label, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb028eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sinusoid_encoding_table(n_seq, d_hidn):\n",
    "    # refs: https://paul-hyun.github.io/transformer-01/\n",
    "    def cal_angle(position, i_hidn):\n",
    "        return position / np.power(10000, 2 * (i_hidn // 2) / d_hidn)\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i_hidn) for i_hidn in range(d_hidn)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(i_seq) for i_seq in range(n_seq)])\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # even index sin \n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # odd index cos\n",
    "\n",
    "    return sinusoid_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00ff0753",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerForClassification(layers.Module):\n",
    "    def __init__(self, embed_size=28, num_heads=7, hidden_dim=256, num_layers=2, num_classes=10, seq_length=28):\n",
    "        super().__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.positional_encoding = np.expand_dims(get_sinusoid_encoding_table(seq_length, embed_size), axis=0)\n",
    "        self.transformer = layers.Transformer(\n",
    "            d_model=embed_size,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=num_layers,\n",
    "            dim_feedforward=hidden_dim,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.fc = layers.Linear(seq_length * embed_size, num_classes)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src += self.positional_encoding[:, :src.shape[1], :]\n",
    "        tgt += self.positional_encoding[:, :tgt.shape[1], :]\n",
    "        output = self.transformer(src, tgt)\n",
    "        flatted_output = self.flatten(output)\n",
    "        out = self.fc(flatted_output)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "debf2ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerForClassification(hidden_dim=hidden_size)\n",
    "criterion = layers.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model, lr_rate=lr_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0cd5c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 10] | Loss: 1.693 | Acc: 0.634\n",
      "Epoch [2 / 10] | Loss: 0.883 | Acc: 0.828\n",
      "Epoch [3 / 10] | Loss: 0.572 | Acc: 0.890\n",
      "Epoch [4 / 10] | Loss: 0.437 | Acc: 0.916\n",
      "Epoch [5 / 10] | Loss: 0.362 | Acc: 0.911\n",
      "Epoch [6 / 10] | Loss: 0.316 | Acc: 0.921\n",
      "Epoch [7 / 10] | Loss: 0.282 | Acc: 0.929\n",
      "Epoch [8 / 10] | Loss: 0.254 | Acc: 0.949\n",
      "Epoch [9 / 10] | Loss: 0.234 | Acc: 0.949\n",
      "Epoch [10 / 10] | Loss: 0.219 | Acc: 0.944\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    total_loss, correct = 0, 0\n",
    "\n",
    "    model.train()\n",
    "    for images, labels in dataloader:\n",
    "        tgt = np.zeros_like(images) # dummpy\n",
    "        logits = model(images, tgt)\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        dz = criterion.backward()\n",
    "        optimizer.update(dz)\n",
    "    \n",
    "    model.eval()\n",
    "    for images, labels in testloader:\n",
    "        tgt = np.zeros_like(images) # dummpy\n",
    "        logits = model(images, tgt)\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "        correct += (predictions == labels).item()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1} / {epochs}] | Loss: {total_loss / len(dataloader):.3f} | Acc: {correct / len(testloader):.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hcrot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
